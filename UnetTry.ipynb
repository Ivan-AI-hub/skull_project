{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MainFunctions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original 512 x 512\n",
    "i_width = 16\n",
    "i_height = 16\n",
    "input_shape = i_width*i_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn = []\n",
    "x_tst = []\n",
    "\n",
    "AddImageToArray(x_trn ,'DICOM\\skulls\\skull8', (i_width, i_height))\n",
    "AddImageToArray(x_tst ,'DICOM\\PA5\\ST1\\SE4', (i_width, i_height))\n",
    "\n",
    "x_trn = np.array(x_trn, np.float32)\n",
    "x_tst = np.array(x_tst, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943.4123\n",
      "234\n",
      "(234, 16, 16)\n",
      "0.14513096\n"
     ]
    }
   ],
   "source": [
    "max_value = np.max(x_trn)\n",
    "print(max_value)\n",
    "x_trn /= max_value\n",
    "x_tst /= max_value\n",
    "\n",
    "showing_ratio = 0.05\n",
    "y_trn = np.where(x_trn > showing_ratio, 1.0, 0.0)\n",
    "y_trn = np.array(y_trn, np.float32)\n",
    "\n",
    "print(len(x_trn ))\n",
    "print(x_trn.shape)\n",
    "print(x_trn[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x2500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "DrawImages(y_trn, 4, (5,5), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "    \n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, inputs):\n",
    "        x = self.up(inputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(1, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024)\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        p1 = self.e1(inputs)\n",
    "        p2 = self.e2(p1)\n",
    "        p3 = self.e3(p2)\n",
    "        p4 = self.e4(p3)\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b)\n",
    "        d2 = self.d2(d1)\n",
    "        d3 = self.d3(d2)\n",
    "        d4 = self.d4(d3)\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        outputs = self.outputs(d4)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = build_unet().to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, criterion, optimizer, train_loader, eps):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for batch_features, targets in train_loader:\n",
    "\n",
    "            batch_features = batch_features.view(-1, 1, i_height, i_width).to(device) #.view(-1, 1, i_height, i_width)\n",
    "            targets = targets.view(-1, 1, i_height, i_width).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute reconstructions\n",
    "            outputs = model(batch_features)\n",
    "            \n",
    "            # compute training reconstruction loss\n",
    "            train_loss = criterion(outputs, targets)\n",
    "            \n",
    "            # compute accumulated gradients\n",
    "            train_loss.backward()\n",
    "            \n",
    "            # perform parameter update based on current gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            loss += train_loss.item()\n",
    "        \n",
    "        # compute the epoch training loss\n",
    "        loss = loss / len(train_loader)\n",
    "        \n",
    "        # display the epoch training loss\n",
    "        print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n",
    "        if loss < eps:\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    (x_trn, x_trn), batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    x_tst, batch_size=32, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/1000, loss = 0.015167\n",
      "epoch : 2/1000, loss = 0.013231\n",
      "epoch : 3/1000, loss = 0.011881\n",
      "epoch : 4/1000, loss = 0.010903\n",
      "epoch : 5/1000, loss = 0.010124\n",
      "epoch : 6/1000, loss = 0.009532\n",
      "epoch : 7/1000, loss = 0.009075\n",
      "epoch : 8/1000, loss = 0.008732\n",
      "epoch : 9/1000, loss = 0.008516\n",
      "epoch : 10/1000, loss = 0.008490\n",
      "epoch : 11/1000, loss = 0.009210\n",
      "epoch : 12/1000, loss = 0.008884\n",
      "epoch : 13/1000, loss = 0.008607\n",
      "epoch : 14/1000, loss = 0.008157\n",
      "epoch : 15/1000, loss = 0.007878\n",
      "epoch : 16/1000, loss = 0.007631\n",
      "epoch : 17/1000, loss = 0.007499\n",
      "epoch : 18/1000, loss = 0.007390\n",
      "epoch : 19/1000, loss = 0.007317\n",
      "epoch : 20/1000, loss = 0.007179\n",
      "epoch : 21/1000, loss = 0.007109\n",
      "epoch : 22/1000, loss = 0.007036\n",
      "epoch : 23/1000, loss = 0.007018\n",
      "epoch : 24/1000, loss = 0.006982\n",
      "epoch : 25/1000, loss = 0.007093\n",
      "epoch : 26/1000, loss = 0.006828\n",
      "epoch : 27/1000, loss = 0.006840\n",
      "epoch : 28/1000, loss = 0.006952\n",
      "epoch : 29/1000, loss = 0.007232\n",
      "epoch : 30/1000, loss = 0.007421\n",
      "epoch : 31/1000, loss = 0.007417\n",
      "epoch : 32/1000, loss = 0.007021\n",
      "epoch : 33/1000, loss = 0.006760\n",
      "epoch : 34/1000, loss = 0.006453\n",
      "epoch : 35/1000, loss = 0.006249\n",
      "epoch : 36/1000, loss = 0.006107\n",
      "epoch : 37/1000, loss = 0.005985\n",
      "epoch : 38/1000, loss = 0.005892\n",
      "epoch : 39/1000, loss = 0.005807\n",
      "epoch : 40/1000, loss = 0.005744\n",
      "epoch : 41/1000, loss = 0.005694\n",
      "epoch : 42/1000, loss = 0.005642\n",
      "epoch : 43/1000, loss = 0.005609\n",
      "epoch : 44/1000, loss = 0.005572\n",
      "epoch : 45/1000, loss = 0.005558\n",
      "epoch : 46/1000, loss = 0.005501\n",
      "epoch : 47/1000, loss = 0.005485\n",
      "epoch : 48/1000, loss = 0.005460\n",
      "epoch : 49/1000, loss = 0.005417\n",
      "epoch : 50/1000, loss = 0.005408\n",
      "epoch : 51/1000, loss = 0.005401\n",
      "epoch : 52/1000, loss = 0.005464\n",
      "epoch : 53/1000, loss = 0.005516\n",
      "epoch : 54/1000, loss = 0.005536\n",
      "epoch : 55/1000, loss = 0.005517\n",
      "epoch : 56/1000, loss = 0.005501\n",
      "epoch : 57/1000, loss = 0.005399\n",
      "epoch : 58/1000, loss = 0.005343\n",
      "epoch : 59/1000, loss = 0.005200\n",
      "epoch : 60/1000, loss = 0.005147\n",
      "epoch : 61/1000, loss = 0.005020\n",
      "epoch : 62/1000, loss = 0.004915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m train(\u001b[39m1000\u001b[39;49m, model, criterion, optimizer, train_loader, \u001b[39m0.003\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, model, criterion, optimizer, train_loader, eps)\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m \u001b[39m# compute reconstructions\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m outputs \u001b[39m=\u001b[39m model(batch_features)\n\u001b[0;32m     13\u001b[0m \u001b[39m# compute training reconstruction loss\u001b[39;00m\n\u001b[0;32m     14\u001b[0m train_loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[1;32mc:\\Users\\ivan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36mbuild_unet.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     23\u001b[0m p4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39me4(p3)\n\u001b[0;32m     24\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Bottleneck \"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb(p4)\n\u001b[0;32m     26\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Decoder \"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m d1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md1(b)\n",
      "File \u001b[1;32mc:\\Users\\ivan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m, in \u001b[0;36mconv_block.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m     13\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m---> 14\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[0;32m     15\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(x)\n\u001b[0;32m     16\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\ivan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ivan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\ivan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(1000, model, criterion, optimizer, train_loader, 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 16, 16)\n",
      "(261, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "test_examples = [[]]\n",
    "reconstruction = []\n",
    "with torch.no_grad():\n",
    "    batch_features = torch.asarray(x_tst)\n",
    "    test_examples = np.array(x_tst)\n",
    "    batch_features = batch_features.view(-1, 1, i_height, i_width).to(device)\n",
    "    reconstruction = np.array(model(batch_features)).reshape(-1, i_height, i_width)\n",
    "\n",
    "print(test_examples.shape)\n",
    "print(reconstruction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32687283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "print(np.max(np.array(reconstruction)))\n",
    "with torch.no_grad():\n",
    "    number = 3\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for index in range(number):\n",
    "        # display original\n",
    "        ax = plt.subplot(4, number, index + 1)\n",
    "        plt.imshow(test_examples[index])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(4, number, index + 1 + number)\n",
    "        plt.imshow(reconstruction[index])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = test_examples * max_value\n",
    "reconstruction = reconstruction * max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308.37585\n"
     ]
    }
   ],
   "source": [
    "print(reconstruction.max())\n",
    "show_ratio = 100\n",
    "v, f = make_mesh(test_examples, show_ratio,1)\n",
    "plt_3d(v, f, 'test_examples.stl')\n",
    "v, f = make_mesh(reconstruction, show_ratio,1)\n",
    "plt_3d(v, f, 'reconstraction.stl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
