{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true},"id":"W9A0ABEVgT_m"},"outputs":[],"source":["import numpy as np\n","from MainFunctions import *\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","from skimage import io, filters\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true},"id":"E5BXOTwcgT_u"},"outputs":[{"name":"stdout","output_type":"stream","text":["16384\n"]}],"source":["#original 512 x 512\n","i_width = 128\n","i_height = 128\n","input_shape = i_width*i_height\n","print(input_shape)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8624,"status":"ok","timestamp":1682021580949,"user":{"displayName":"Иван Иванович","userId":"03577582405859228630"},"user_tz":-180},"id":"rbcaE_YIgT_w","outputId":"57875781-8853-47af-9368-571b20ded019"},"outputs":[{"name":"stdout","output_type":"stream","text":["(269, 128, 128)\n"]}],"source":["x_trn = []\n","x_tst = []\n","\n","AddImageToArray(x_trn ,'DICOM/PA2/ST1/SE4', (i_width, i_height))\n","AddImageToArray(x_tst ,'DICOM/PA5/ST1/SE4', (i_width, i_height))\n","\n","x_trn = np.array(x_trn, np.float32)\n","x_tst = np.array(x_tst, np.float32)\n","print(x_trn.shape)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qILjcJRFgT_x"},"outputs":[],"source":["x_trn = segmentation(x_trn, 21,21)\n","x_tst = segmentation(x_tst, 25,16)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ivan_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n","  warnings.warn(\n"]}],"source":["from sklearn.cluster import AffinityPropagation\n","clusterisation_method = AffinityPropagation(random_state=4114)\n","labels = clusterisation_method.fit_predict(np.reshape(x_trn, (-1, input_shape)))\n","output_shape = labels.max()+1\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def to_categorical(y, num_classes):\n","    \"\"\" 1-hot encodes a tensor \"\"\"\n","    return np.eye(num_classes, dtype='uint8')[y]\n","\n","y_categorical = to_categorical(labels, output_shape)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class build_LayerClassificator(nn.Module):\n","    def __init__(self, inp_shape, out_shape):\n","        super().__init__()\n","        \"\"\"Classificator\"\"\"\n","        self.flatten = nn.Flatten()\n","        self.fully_connected1 = nn.Linear(int(inp_shape), out_shape)\n","        self.softmax = nn.Softmax(dim=1)\n","    def forward(self, inputs):\n","        x = self.flatten(inputs)\n","        x = self.fully_connected1(x)\n","        x = self.softmax(x)\n","        return x"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["#use gpu if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# create a model from `AE` autoencoder class\n","# load it to the specified device, either gpu or cpu\n","model = build_LayerClassificator(input_shape, output_shape).to(device)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def train(epochs, model, criterion, optimizer, train_loader, eps):\n","    for epoch in range(epochs):\n","        loss = 0\n","        for batch_features, targets in train_loader:\n","            batch_features = batch_features.view(-1, 1, i_height, i_width).to(device)\n","            targets = targets.to(device)\n","            optimizer.zero_grad()\n","            \n","            # compute reconstructions\n","            outputs = model(batch_features)\n","            # compute training reconstruction loss\n","            train_loss = criterion(outputs, targets)\n","            \n","            # compute accumulated gradients\n","            train_loss.backward()\n","            \n","            # perform parameter update based on current gradients\n","            optimizer.step()\n","            \n","            # add the mini-batch training loss to epoch loss\n","            loss += train_loss.item()\n","        \n","        # compute the epoch training loss\n","        loss = loss / len(train_loader)\n","        \n","        # display the epoch training loss\n","        print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))\n","        if loss < eps:\n","            break\n","    \n","    return model"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# create an optimizer object\n","# Adam optimizer with learning rate 1e-3\n","optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-3)\n","\n","# mean-squared error loss\n","criterion = nn.MSELoss()\n","\n","tensor_x = torch.Tensor(x_trn) # transform to torch tensor\n","tensor_y = torch.Tensor(y_categorical)\n","\n","my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n","my_dataloader = DataLoader(my_dataset) # create your dataloader\n","\n","train_loader = DataLoader(\n","    my_dataset, batch_size=64, shuffle=True\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch : 1/1000, loss = 0.023546\n","epoch : 2/1000, loss = 0.012068\n","epoch : 3/1000, loss = 0.009115\n","epoch : 4/1000, loss = 0.006652\n","epoch : 5/1000, loss = 0.006312\n","epoch : 6/1000, loss = 0.005843\n"]}],"source":["model = train(1000, model, criterion, optimizer, train_loader, 0.006)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["with torch.no_grad():\n","    batch_features = torch.asarray(x_trn)\n","    batch_features = batch_features.view(-1, 1, i_height, i_width).to(device)\n","    pred = np.array(model(batch_features ))"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0]\n"]}],"source":["print(labels-np.argmax(pred,1))"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"1ym7TGvyRclOIClduMiWldoGXcSgOeC7p","timestamp":1681938048504}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
